{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0B5dFGnuPjPA",
        "outputId": "888cc0d2-6d27-4b82-f1c7-1d9633f43fde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.31.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, faiss-cpu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed faiss-cpu-1.11.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers faiss-cpu pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "85d6a9ae9da14980a5e1f0947a8fa2c5",
            "009902a47b22452e9ae19fbec54a8e80",
            "c6dba49a6f854e6ab9493a25a7b2f320",
            "1134a900feb74d3bbca5ef2dfbde05f7",
            "59c22a57b4da4279b76fad8a5a3f3e52",
            "a494c599d35d45e9b5f7170e6cac22bc",
            "2c0927422baf43ddbaea586b009663a4",
            "9c1e108ea10e4466b1a41950a91c0163",
            "a44822d0096e49d59d9ee19f5e4eb7a6",
            "e7a2bac801e84aa78e61bae1a46afbbc",
            "d5eff461fca044ca9c8193e16f519585"
          ]
        },
        "id": "fv3T9QShPuUw",
        "outputId": "71057e3e-b21b-4177-c37c-fe7f33b0d86a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-1eb806c9ce81>:8: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(\"/content/cleaned_movie_quotes_final_i_think.csv\")  # Update with your actual filename\n",
            "<ipython-input-3-1eb806c9ce81>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['text'] = df['text'].astype(str)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating embeddings...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85d6a9ae9da14980a5e1f0947a8fa2c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/9509 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FAISS index built with 304269 vectors.\n",
            "Index and metadata saved.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import faiss\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# === 1. Load Cleaned CSV ===\n",
        "df = pd.read_csv(\"/content/cleaned_movie_quotes_final_i_think.csv\")  # Update with your actual filename\n",
        "\n",
        "# === 2. Load Embedding Model ===\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')  # Fast + accurate\n",
        "# Drop rows with missing text\n",
        "df = df.dropna(subset=['text'])\n",
        "\n",
        "# Ensure all text is string type\n",
        "df['text'] = df['text'].astype(str)\n",
        "# === 3. Generate Embeddings for the 'text' Column ===\n",
        "print(\"Generating embeddings...\")\n",
        "embeddings = model.encode(df['text'].tolist(), show_progress_bar=True, convert_to_numpy=True)\n",
        "\n",
        "# === 4. Build FAISS Index ===\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(embeddings)\n",
        "print(f\"FAISS index built with {index.ntotal} vectors.\")\n",
        "\n",
        "# === 5. Save FAISS index and metadata ===\n",
        "faiss.write_index(index, \"quote_index.faiss\")\n",
        "df.to_pickle(\"quote_metadata.pkl\")  # Stores text + metadata\n",
        "np.save(\"quote_embeddings.npy\", embeddings)\n",
        "\n",
        "print(\"Index and metadata saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgg3S6dMSRNm",
        "outputId": "8dbe0ade-22a0-4df4-9ae1-f7b183bbd90a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Remaining rows after dropping missing text: 304269\n"
          ]
        }
      ],
      "source": [
        "print(\"Remaining rows after dropping missing text:\", len(df))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl_j-L5CTUGr",
        "outputId": "c94cafa8-1e1c-4cc5-a1d4-95b3baf4992c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 5 results for: \"I'm the king of the world!\"\n",
            "\n",
            "Result #1\n",
            "Text   : im the king of the world\n",
            "Char   : JULIE\n",
            "Title  : i still know what you did last summer (1998)\n",
            "Genre  : ['horror', 'mystery', 'thriller']\n",
            "Gender : f\n",
            "Score  : 0.2170\n",
            "\n",
            "Result #2\n",
            "Text   : no im the king of the world\n",
            "Char   : KARLA\n",
            "Title  : i still know what you did last summer (1998)\n",
            "Genre  : ['horror', 'mystery', 'thriller']\n",
            "Gender : f\n",
            "Score  : 0.3822\n",
            "\n",
            "Result #3\n",
            "Text   : i am your king\n",
            "Char   : ARTHUR\n",
            "Title  : monty python and the holy grail (1975)\n",
            "Genre  : ['adventure', 'comedy']\n",
            "Gender : m\n",
            "Score  : 0.4937\n",
            "\n",
            "Result #4\n",
            "Text   : well  i am king\n",
            "Char   : ARTHUR\n",
            "Title  : monty python and the holy grail (1975)\n",
            "Genre  : ['adventure', 'comedy']\n",
            "Gender : m\n",
            "Score  : 0.5374\n",
            "\n",
            "Result #5\n",
            "Text   : im im not the king\n",
            "Char   : CHARLES\n",
            "Title  : the messenger (2009)\n",
            "Genre  : ['drama', 'romance', 'war']\n",
            "Gender : m\n",
            "Score  : 0.5577\n"
          ]
        }
      ],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# === 1. Load the index, metadata, and model ===\n",
        "index = faiss.read_index(\"quote_index.faiss\")\n",
        "metadata = pd.read_pickle(\"quote_metadata.pkl\")\n",
        "embeddings = np.load(\"quote_embeddings.npy\")  # Optional, not required for search\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# === 2. Define retrieval function ===\n",
        "def retrieve_similar_quotes(query, top_k=5):\n",
        "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "\n",
        "    print(f\"\\nTop {top_k} results for: \\\"{query}\\\"\")\n",
        "    for i, idx in enumerate(indices[0]):\n",
        "        row = metadata.iloc[idx]\n",
        "        print(f\"\\nResult #{i+1}\")\n",
        "        print(f\"Text   : {row['text']}\")\n",
        "        print(f\"Char   : {row['character_name']}\")\n",
        "        print(f\"Title  : {row['title']} ({row['year']})\")\n",
        "        print(f\"Genre  : {row['genres']}\")\n",
        "        print(f\"Gender : {row['gender']}\")\n",
        "        print(f\"Score  : {distances[0][i]:.4f}\")\n",
        "\n",
        "# === 3. Try a test query ===\n",
        "retrieve_similar_quotes(\"I'm the king of the world!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGSZV2cATjTE",
        "outputId": "43ddf5f0-2a70-47f7-8cec-4121abd84a25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 5 results for: \"I'm done.\"\n",
            "\n",
            "Result #1\n",
            "Text   : im done\n",
            "Char   : DANA\n",
            "Title  : true lies (1994)\n",
            "Genre  : ['action', 'thriller']\n",
            "Gender : unknown\n",
            "Score  : 0.6939\n",
            "\n",
            "Result #2\n",
            "Text   : you done\n",
            "Char   : LORETTA\n",
            "Title  : the sting (1973)\n",
            "Genre  : ['comedy', 'crime', 'drama']\n",
            "Gender : f\n",
            "Score  : 0.8062\n",
            "\n",
            "Result #3\n",
            "Text   : you done\n",
            "Char   : PONY\n",
            "Title  : suburbia (1996)\n",
            "Genre  : ['comedy', 'drama']\n",
            "Gender : m\n",
            "Score  : 0.8062\n",
            "\n",
            "Result #4\n",
            "Text   : well im done  are you done\n",
            "Char   : JEFFREY\n",
            "Title  : buffy the vampire slayer (1992)\n",
            "Genre  : ['horror', 'comedy', 'action']\n",
            "Gender : m\n",
            "Score  : 0.8539\n",
            "\n",
            "Result #5\n",
            "Text   : done what\n",
            "Char   : HILDY\n",
            "Title  : his girl friday (1940)\n",
            "Genre  : ['comedy', 'drama', 'romance']\n",
            "Gender : f\n",
            "Score  : 0.8906\n"
          ]
        }
      ],
      "source": [
        "retrieve_similar_quotes(\"I'm done.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfGpntpdTpjv",
        "outputId": "7458697a-be9e-461c-bad3-299862753093"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 5 results for: \"I'm not a bad person.\"\n",
            "\n",
            "Result #1\n",
            "Text   : i am not a bad man\n",
            "Char   : PORTER\n",
            "Title  : the third man (1949)\n",
            "Genre  : ['film-noir', 'mystery', 'thriller']\n",
            "Gender : m\n",
            "Score  : 0.3631\n",
            "\n",
            "Result #2\n",
            "Text   : im a bad person\n",
            "Char   : JIMMY\n",
            "Title  : magnolia (1999)\n",
            "Genre  : ['drama']\n",
            "Gender : m\n",
            "Score  : 0.4389\n",
            "\n",
            "Result #3\n",
            "Text   : you know im a good person\n",
            "Char   : ROB\n",
            "Title  : high fidelity (2000)\n",
            "Genre  : ['comedy', 'drama', 'music', 'romance']\n",
            "Gender : m\n",
            "Score  : 0.6756\n",
            "\n",
            "Result #4\n",
            "Text   : im always bad\n",
            "Char   : AGNES\n",
            "Title  : agnes of god (1985)\n",
            "Genre  : ['drama', 'mystery', 'thriller']\n",
            "Gender : f\n",
            "Score  : 0.6964\n",
            "\n",
            "Result #5\n",
            "Text   : im a bad girl im a bad girl\n",
            "Char   : CAMMI\n",
            "Title  : sideways (2004)\n",
            "Genre  : ['comedy', 'drama', 'romance']\n",
            "Gender : unknown\n",
            "Score  : 0.7291\n"
          ]
        }
      ],
      "source": [
        "retrieve_similar_quotes(\"I'm not a bad person.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjF7M07WV0PU"
      },
      "source": [
        "# RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RAEQtNB8XVdp",
        "outputId": "b868aacb-32e7-476d-f83d-c1173050ba22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.169.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-generativeai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "Htb9M4wqV2Cy",
        "outputId": "96b193d8-4bea-496f-d7d5-bf47f2d23b36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the Movie Quote RAG system with Gemini LLM.\n",
            "\n",
            "Enter your query (or 'exit' to quit): Find a funny quote about work.\n",
            "\n",
            "Top 5 similar quotes:\n",
            "1. \"talk about work never\" — MILO (antitrust) [Genres: ['drama', 'thriller']]\n",
            "2. \"work work work is that all that you do\" — THEO (scary movie 2) [Genres: ['comedy']]\n",
            "3. \"you find any work\" — LULA (wild at heart) [Genres: ['crime', 'romance', 'thriller']]\n",
            "4. \"lets talk about the work that you care so much about\" — FRANK BRAND (simone) [Genres: ['short', 'drama', 'horror', 'thriller']]\n",
            "5. \"actually its not about work its advice about\" — BEN (the ice storm) [Genres: ['drama']]\n",
            "\n",
            "Generated response from Gemini LLM:\n",
            " \"work work work is that all that you do\" — THEO (scary movie 2)\n",
            "\n",
            "\n",
            "Enter your query (or 'exit' to quit): a funny and yet deep quote about life\n",
            "\n",
            "Top 5 similar quotes:\n",
            "1. \"life i said life\" — ANNIE (annie hall) [Genres: ['comedy', 'drama', 'romance']]\n",
            "2. \"life is only life when it is bounded by death  the inheritance is death the gift is the finality of life to be part of the fabric  the inside  i love you brenna\" — TAUPIN (highlander) [Genres: ['action', 'fantasy']]\n",
            "3. \"its about life\" — ANN (state and main) [Genres: ['comedy', 'drama']]\n",
            "4. \"life\" — MUMFORD (mumford) [Genres: ['comedy', 'drama']]\n",
            "5. \"your life and that of others\" — AROJAZ (1492: conquest of paradise) [Genres: ['adventure', 'biography', 'drama', 'history']]\n",
            "\n",
            "Generated response from Gemini LLM:\n",
            " Given the provided quotes, there isn't one that perfectly fits \"funny and yet deep.\"  The quotes range from existential (\"life is only life when it is bounded by death\") to simply stating the word \"life.\"\n",
            "\n",
            "To create a suitable answer, we need to invent one:\n",
            "\n",
            "**\"Life is like a really bad improv show – you're given a terrible script, a bizarre costume, and you're expected to make it work. But hey, at least the audience is always laughing… eventually.\"**\n",
            "\n",
            "This attempts to capture both the absurdity and the inherent seriousness of life's unpredictable nature.\n",
            "\n",
            "\n",
            "Enter your query (or 'exit' to quit): exit\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import faiss\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import google.generativeai as genai\n",
        "\n",
        "# === 1. Initialize Gemini API key ===\n",
        "genai.configure(api_key=\"AIzaSyDDaUTEWZGkEvfT46SVH_qOs_QPQJcHLsg\")  # replace with your actual key\n",
        "\n",
        "# Initialize the GenerativeModel\n",
        "model_genai = genai.GenerativeModel('gemini-1.5-flash') # Use the correct model name\n",
        "\n",
        "# === 2. Load cleaned data and embeddings ===\n",
        "df = pd.read_pickle(\"quote_metadata.pkl\")        # your cleaned data with metadata\n",
        "embeddings = np.load(\"quote_embeddings.npy\")     # precomputed embeddings\n",
        "index = faiss.read_index(\"quote_index.faiss\")    # FAISS index\n",
        "\n",
        "# === 3. Load embedding model for queries ===\n",
        "model_embedding = SentenceTransformer('all-MiniLM-L6-v2') # Renamed to avoid confusion with genai model\n",
        "\n",
        "def retrieve_similar_quotes(query, top_k=5):\n",
        "    # Embed the query\n",
        "    query_vec = model_embedding.encode([query], convert_to_numpy=True) # Use the embedding model\n",
        "\n",
        "    # Search in FAISS index\n",
        "    D, I = index.search(query_vec, top_k)\n",
        "\n",
        "    # Retrieve corresponding quotes from df\n",
        "    results = []\n",
        "    for idx in I[0]:\n",
        "        row = df.iloc[idx]\n",
        "        text = row['text']\n",
        "        char = row.get('character_name', 'Unknown')\n",
        "        title = row.get('title', 'Unknown')\n",
        "        genres = row.get('genres', [])\n",
        "        results.append(f'\"{text}\" — {char} ({title}) [Genres: {genres}]')\n",
        "    return results\n",
        "\n",
        "def generate_response_with_context(user_query, retrieved_quotes):\n",
        "    # Combine retrieved quotes as context for Gemini\n",
        "    context_str = \"\\n\".join(retrieved_quotes)\n",
        "    full_prompt = f\"Here are some relevant movie quotes:\\n{context_str}\\n\\nUser question: {user_query}\\nAnswer:\"\n",
        "\n",
        "    # Use the GenerativeModel to generate content\n",
        "    # The generate_content method accepts a prompt directly\n",
        "    response = model_genai.generate_content(\n",
        "        full_prompt,\n",
        "        generation_config=genai.GenerationConfig( # Use GenerationConfig for parameters\n",
        "            temperature=0.7,\n",
        "            max_output_tokens=256,\n",
        "        )\n",
        "    )\n",
        "    # Access the generated text via .text\n",
        "    return response.text\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Welcome to the Movie Quote RAG system with Gemini LLM.\")\n",
        "    while True:\n",
        "        user_query = input(\"\\nEnter your query (or 'exit' to quit): \").strip()\n",
        "        if user_query.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "        # Step 1: Retrieve similar quotes\n",
        "        retrieved = retrieve_similar_quotes(user_query, top_k=5)\n",
        "        print(\"\\nTop 5 similar quotes:\")\n",
        "        for i, quote in enumerate(retrieved, 1):\n",
        "            print(f\"{i}. {quote}\")\n",
        "\n",
        "        # Step 2: Generate answer with Gemini LLM\n",
        "        answer = generate_response_with_context(user_query, retrieved)\n",
        "        print(\"\\nGenerated response from Gemini LLM:\\n\", answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "id": "3InAg_oaaFnH",
        "outputId": "af307bd5-15f0-4ef5-91cb-b973e4e408c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the Movie Quote RAG system with Gemini LLM.\n",
            "\n",
            "Enter your query (or 'exit' to quit): a romantic quote\n",
            "\n",
            "Top 5 similar quotes:\n",
            "1. \"very romantic\" — JOSIE (never been kissed) [Genres: ['comedy', 'drama', 'romance']]\n",
            "2. \"how romantic\" — PHILBY (the time machine) [Genres: ['sci-fi', 'adventure', 'action']]\n",
            "3. \"how romantic\" — IKE (runaway bride) [Genres: ['comedy', 'romance']]\n",
            "4. \"that is so romantic\" — JULIANNE (my best friend's wedding) [Genres: ['comedy', 'romance']]\n",
            "5. \"just a romantic thats you\" — VIVIAN (pretty woman) [Genres: ['comedy', 'romance']]\n",
            "\n",
            "Generated response from Gemini LLM:\n",
            " \"Very romantic,\" \"How romantic,\" and \"That is so romantic\" are all good options, depending on the desired tone.  \"Just a romantic that's you\" is also a possibility, but it's less a statement of romanticism and more a description of someone.\n",
            "\n",
            "\n",
            "Enter your query (or 'exit' to quit): a deep quote about friendship that suit for two childhood friends\n",
            "\n",
            "Top 5 similar quotes:\n",
            "1. \"quite any childhood friends enemies\" — STEED (the avengers) [Genres: ['action', 'adventure', 'thriller']]\n",
            "2. \"that we should take our friendship a little further\" — CINDY (scary movie 2) [Genres: ['comedy']]\n",
            "3. \"friends gentlemen they were friends\" — SMECKER (the boondock saints) [Genres: ['action', 'crime', 'drama', 'thriller']]\n",
            "4. \"who was the friend\" — CRUZ (out of sight) [Genres: ['comedy', 'crime', 'romance', 'thriller']]\n",
            "5. \"whats the name of your childs best friend\" — HOUSECAT (catwoman) [Genres: ['action', 'crime', 'fantasy']]\n",
            "\n",
            "Generated response from Gemini LLM:\n",
            " Here are a few options for a deep quote about friendship suitable for two childhood friends, drawing inspiration from the provided movie quotes:\n",
            "\n",
            "**Option 1 (Focus on lasting bond):**\n",
            "\n",
            "\"Through thick and thin, laughter and tears,  our friendship has been the constant thread weaving through the tapestry of our lives.  It's not just a memory of childhood, but a promise for the future.\"\n",
            "\n",
            "\n",
            "**Option 2 (Acknowledging complexities):**\n",
            "\n",
            "\"We've been friends since we were kids,  sometimes rivals, sometimes allies, always bound by a shared history that runs deeper than any single moment.  That's the true measure of friendship, isn't it?\"\n",
            "\n",
            "\n",
            "**Option 3 (More melancholic/reflective):**\n",
            "\n",
            "\"Sometimes I wonder if it's the shared memories or the unspoken understanding that makes our friendship so enduring.  Whatever it is,  it's a precious thing, a gift we shouldn't take for granted.\"\n",
            "\n",
            "\n",
            "**Option 4 (Simple and direct):**\n",
            "\n",
            "\"Childhood friends.  That means something. It means a bond forged in innocence, tested by time, and strengthened by shared experiences.\"\n",
            "\n",
            "\n",
            "The best option will depend on the specific tone and context you're aiming for\n",
            "\n",
            "Enter your query (or 'exit' to quit): exit\n"
          ]
        }
      ],
      "source": [
        "print(\"Welcome to the Movie Quote RAG system with Gemini LLM.\")\n",
        "while True:\n",
        "  user_query = input(\"\\nEnter your query (or 'exit' to quit): \").strip()\n",
        "  if user_query.lower() == 'exit':\n",
        "    break\n",
        "\n",
        "  # Step 1: Retrieve similar quotes\n",
        "  retrieved = retrieve_similar_quotes(user_query, top_k=5)\n",
        "  print(\"\\nTop 5 similar quotes:\")\n",
        "  for i, quote in enumerate(retrieved, 1):\n",
        "    print(f\"{i}. {quote}\")\n",
        "\n",
        "  # Step 2: Generate answer with Gemini LLM\n",
        "  answer = generate_response_with_context(user_query, retrieved)\n",
        "  print(\"\\nGenerated response from Gemini LLM:\\n\", answer)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "009902a47b22452e9ae19fbec54a8e80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a494c599d35d45e9b5f7170e6cac22bc",
            "placeholder": "​",
            "style": "IPY_MODEL_2c0927422baf43ddbaea586b009663a4",
            "value": "Batches: 100%"
          }
        },
        "1134a900feb74d3bbca5ef2dfbde05f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7a2bac801e84aa78e61bae1a46afbbc",
            "placeholder": "​",
            "style": "IPY_MODEL_d5eff461fca044ca9c8193e16f519585",
            "value": " 9509/9509 [01:28&lt;00:00, 120.23it/s]"
          }
        },
        "2c0927422baf43ddbaea586b009663a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59c22a57b4da4279b76fad8a5a3f3e52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85d6a9ae9da14980a5e1f0947a8fa2c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_009902a47b22452e9ae19fbec54a8e80",
              "IPY_MODEL_c6dba49a6f854e6ab9493a25a7b2f320",
              "IPY_MODEL_1134a900feb74d3bbca5ef2dfbde05f7"
            ],
            "layout": "IPY_MODEL_59c22a57b4da4279b76fad8a5a3f3e52"
          }
        },
        "9c1e108ea10e4466b1a41950a91c0163": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a44822d0096e49d59d9ee19f5e4eb7a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a494c599d35d45e9b5f7170e6cac22bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6dba49a6f854e6ab9493a25a7b2f320": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c1e108ea10e4466b1a41950a91c0163",
            "max": 9509,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a44822d0096e49d59d9ee19f5e4eb7a6",
            "value": 9509
          }
        },
        "d5eff461fca044ca9c8193e16f519585": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7a2bac801e84aa78e61bae1a46afbbc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
